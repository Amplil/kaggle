{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NLP - LASER Embeddings + Keras\n\nThis approach encodes the tweets using [LASER](https://github.com/yannvgn/laserembeddings) multilingual sentence embeddings,\nfollowed by a [TF Keras](https://www.tensorflow.org/api_docs/python/tf/keras) dense neural network.","metadata":{}},{"cell_type":"code","source":"!pip install -q laserembeddings laserembeddings[zh] laserembeddings[ja]\n!pip install -q ftfy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import fasttext\nimport ftfy\nimport html\nimport laserembeddings\nimport numpy as np\nimport pandas as pd\nimport re\nimport tensorflow as tf\nimport sys\n\nfrom fastcache import clru_cache\nfrom laserembeddings import Laser\nfrom typing import List, Union\nfrom urllib.parse import unquote\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/nlp-getting-started/train.csv', index_col=0).fillna('')\ndf_test  = pd.read_csv('../input/nlp-getting-started/test.csv',  index_col=0).fillna('')\ndf_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess Text\n\nKeyword, location and text fields into a single string. \n\nSimple preprocessing is performed to remove HTML and encoded elements, @usernames, hashtag prefixes and urls.","metadata":{}},{"cell_type":"code","source":"def preprocess_text(df):\n    texts = df[['keyword', 'location', 'text']].agg(' '.join, axis=1)\n    texts = texts.apply(ftfy.fix_text)   # fix \\x89\n    texts = texts.apply(html.unescape)  \n    texts = texts.apply(unquote)         # remove %20\n    texts = texts.apply(lambda s: re.sub('@\\w+', ' ', s))            # remove @usernames\n    texts = texts.apply(lambda s: re.sub('#',    ' ', s))            # remove hashtag prefixes    \n    texts = texts.apply(lambda s: re.sub('\\n',   ' ', s))            # remove newlines\n    texts = texts.apply(lambda s: re.sub('\\w+://\\S+',  '<URL>', s))  # remove urls    \n    texts = texts.apply(lambda s: re.sub('\\s+',  ' ', s))            # remove multiple spaces    \n    return list(texts)\n    \npreprocess_text(df_train)[:10]\npreprocess_text(df_test)[:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LASER Embeddings\n\nThis encodes each of the strings as a LASER embedding (1024 dimentional vector)","metadata":{}},{"cell_type":"code","source":"%%bash\n# DOCS: https://github.com/facebookresearch/LASER/blob/master/install_models.sh\n\nmkdir -p models/laser/\n# for FILE in bilstm.eparl21.2018-11-19.pt eparl21.fcodes eparl21.fvocab bilstm.93langs.2018-12-26.pt 93langs.fcodes 93langs.fvocab; do\nfor FILE in bilstm.93langs.2018-12-26.pt 93langs.fcodes 93langs.fvocab; do\n    wget -cq https://dl.fbaipublicfiles.com/laser/models/$FILE -O models/laser/$FILE\ndone","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from config import config\n# from src.utils.fasttest_model import language_detect\n# from src.utils.punkt_tokenizer import punkt_tokenize_sentences\n\nconfig = {\n    \"laser\": {\n        \"base_dir\":  \"./models/laser\",\n        \"bpe_codes\": \"./models/laser/93langs.fcodes\",\n        \"bpe_vocab\": \"./models/laser/93langs.fvocab\",\n        \"encoder\":   \"./models/laser/bilstm.93langs.2018-12-26.pt\",\n    }\n}\n\n# Instantiate encoder\n# BUG: CUDA GPU memory is exceeded if both laser and labse are loaded together \n# @clru_cache(None)\ndef get_laser_model():\n    laser_model = Laser(\n        bpe_codes = config['laser']['bpe_codes'],\n        bpe_vocab = config['laser']['bpe_vocab'],\n        encoder   = config['laser']['encoder'],\n        tokenizer_options = None,\n        embedding_options = None\n    )\n    return laser_model\n\n\ndef laser_encode(text: Union[str, List[str]], lang='en', normalize=True) -> np.ndarray:\n    \"\"\"\n    Encodes a corpus of text using LASER\n    :param text: Large block of text (will be tokenized), or list of pre-tokenized sentences\n    :param lang: 2 digit language code (optional autodetect)\n    :return:     embedding matrix\n    \"\"\"\n    laser_model = get_laser_model()\n    \n    # lang = lang or language_detect(text, threshold=0.0)\n    if isinstance(text, str):\n        # sentences = punkt_tokenize_sentences(text, lang=lang)\n        sentences = [ text ]\n    else:\n        sentences = list(text)\n\n    embedding = laser_model.embed_sentences(sentences, lang=lang)\n    \n    if normalize:\n        embedding = embedding / np.sqrt(np.sum(embedding**2, axis=1)).reshape(-1,1)\n        \n    return embedding","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\nX_train = laser_encode(preprocess_text(df_train))\nY_train = df_train['target']\n\nprint('X_train.shape', X_train.shape)\nprint('Y_train.shape', Y_train.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Neural Network - TF Keras\n\nDefine and train a dense neural network. \n\nThis inputs a 1024 LASER embedding and outputs a 1 bit classification prediction.\n\nA triangular shaped architecture is used, including Dropout and BatchNorm.","metadata":{}},{"cell_type":"code","source":"# DOCS: https://keras.io/examples/keras_recipes/antirectifier/\n\n# Build the model\nmodel = tf.keras.Sequential([\n    tf.keras.Input(shape=(1024,)),\n    tf.keras.layers.Dense(512, activation=tf.keras.layers.LeakyReLU(alpha=0.1)),\n        tf.keras.layers.Dropout(0.25),\n        tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(128, activation=tf.keras.layers.LeakyReLU(alpha=0.1)),\n        tf.keras.layers.Dropout(0.25),\n        tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(32, activation=tf.keras.layers.LeakyReLU(alpha=0.1)),\n        tf.keras.layers.Dropout(0.25),\n        tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(8, activation=tf.keras.layers.LeakyReLU(alpha=0.1)),\n        tf.keras.layers.Dropout(0.25),\n        tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid),\n])\n\"\"\"\nmodel = tf.keras.Sequential([\n    tf.keras.Input(shape=(1024,)),\n    tf.keras.layers.Dense(512, activation=tf.keras.layers.LeakyReLU(alpha=0.1)),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Dense(128, activation=tf.keras.layers.LeakyReLU(alpha=0.1)),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Dense(32, activation=tf.keras.layers.LeakyReLU(alpha=0.1)),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Dense(8, activation=tf.keras.layers.LeakyReLU(alpha=0.1)),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid),\n])\n\"\"\"\n\ndef model_compile_fit(model, X, Y):\n    log_dir = 'logs'\n    model.summary()\n    \n    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)\n        \n    # Compile the model\n    model.compile(\n        loss      = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n        # optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001),\n        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5),\n        metrics   = [ tf.keras.metrics.BinaryAccuracy() ],\n    )\n    \n    # Train the model\n    # add history and tensorboard\n    history=model.fit(\n        X_train, Y_train, \n        batch_size = 32, \n        epochs     = 1000, \n        validation_split = 0.2,\n        callbacks = [\n            tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10),\n            tf.keras.callbacks.ModelCheckpoint('model.h5',  monitor='binary_accuracy', mode='max', verbose=0, save_best_only=True),\n            tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n        ],\n        verbose=2\n    )\n    model.save('model.h5')\n    \n    print()\n    print('Train Accuracy')\n    model.evaluate(X_train, Y_train)\n\n    print('Test Accuracy')\n    model.evaluate(X_test, Y_test)\n    return history\n\n    \nhistory=model_compile_fit(model, X_train, Y_train)","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_20 (Dense)             (None, 512)               524800    \n_________________________________________________________________\ndropout_16 (Dropout)         (None, 512)               0         \n_________________________________________________________________\nbatch_normalization_16 (Batc (None, 512)               2048      \n_________________________________________________________________\ndense_21 (Dense)             (None, 128)               65664     \n_________________________________________________________________\ndropout_17 (Dropout)         (None, 128)               0         \n_________________________________________________________________\nbatch_normalization_17 (Batc (None, 128)               512       \n_________________________________________________________________\ndense_22 (Dense)             (None, 32)                4128      \n_________________________________________________________________\ndropout_18 (Dropout)         (None, 32)                0         \n_________________________________________________________________\nbatch_normalization_18 (Batc (None, 32)                128       \n_________________________________________________________________\ndense_23 (Dense)             (None, 8)                 264       \n_________________________________________________________________\ndropout_19 (Dropout)         (None, 8)                 0         \n_________________________________________________________________\nbatch_normalization_19 (Batc (None, 8)                 32        \n_________________________________________________________________\ndense_24 (Dense)             (None, 1)                 9         \n=================================================================\nTotal params: 597,585\nTrainable params: 596,225\nNon-trainable params: 1,360\n_________________________________________________________________\nEpoch 1/1000\n172/172 - 1s - loss: 0.7621 - binary_accuracy: 0.5141 - val_loss: 0.7480 - val_binary_accuracy: 0.5565\nEpoch 2/1000\n172/172 - 1s - loss: 0.7542 - binary_accuracy: 0.5445 - val_loss: 0.7420 - val_binary_accuracy: 0.6389\nEpoch 3/1000\n172/172 - 1s - loss: 0.7515 - binary_accuracy: 0.5595 - val_loss: 0.7345 - val_binary_accuracy: 0.6572\nEpoch 4/1000\n172/172 - 1s - loss: 0.7450 - binary_accuracy: 0.5849 - val_loss: 0.7251 - val_binary_accuracy: 0.6601\nEpoch 5/1000\n172/172 - 1s - loss: 0.7405 - binary_accuracy: 0.5973 - val_loss: 0.7185 - val_binary_accuracy: 0.6659\nEpoch 6/1000\n172/172 - 1s - loss: 0.7408 - binary_accuracy: 0.5995 - val_loss: 0.7151 - val_binary_accuracy: 0.6740\nEpoch 7/1000\n172/172 - 1s - loss: 0.7355 - binary_accuracy: 0.6155 - val_loss: 0.7115 - val_binary_accuracy: 0.6849\nEpoch 8/1000\n172/172 - 1s - loss: 0.7330 - binary_accuracy: 0.6197 - val_loss: 0.7097 - val_binary_accuracy: 0.6951\nEpoch 9/1000\n172/172 - 1s - loss: 0.7294 - binary_accuracy: 0.6392 - val_loss: 0.7061 - val_binary_accuracy: 0.6995\nEpoch 10/1000\n172/172 - 1s - loss: 0.7288 - binary_accuracy: 0.6283 - val_loss: 0.7042 - val_binary_accuracy: 0.7046\nEpoch 11/1000\n172/172 - 1s - loss: 0.7263 - binary_accuracy: 0.6429 - val_loss: 0.7019 - val_binary_accuracy: 0.7090\nEpoch 12/1000\n172/172 - 1s - loss: 0.7240 - binary_accuracy: 0.6557 - val_loss: 0.7004 - val_binary_accuracy: 0.7126\nEpoch 13/1000\n172/172 - 1s - loss: 0.7221 - binary_accuracy: 0.6504 - val_loss: 0.6966 - val_binary_accuracy: 0.7214\nEpoch 14/1000\n172/172 - 1s - loss: 0.7183 - binary_accuracy: 0.6728 - val_loss: 0.6971 - val_binary_accuracy: 0.7236\nEpoch 15/1000\n172/172 - 1s - loss: 0.7186 - binary_accuracy: 0.6662 - val_loss: 0.6931 - val_binary_accuracy: 0.7279\nEpoch 16/1000\n172/172 - 1s - loss: 0.7157 - binary_accuracy: 0.6759 - val_loss: 0.6933 - val_binary_accuracy: 0.7301\nEpoch 17/1000\n172/172 - 1s - loss: 0.7125 - binary_accuracy: 0.6900 - val_loss: 0.6914 - val_binary_accuracy: 0.7330\nEpoch 18/1000\n172/172 - 1s - loss: 0.7140 - binary_accuracy: 0.6792 - val_loss: 0.6894 - val_binary_accuracy: 0.7367\nEpoch 19/1000\n172/172 - 1s - loss: 0.7115 - binary_accuracy: 0.6894 - val_loss: 0.6880 - val_binary_accuracy: 0.7411\nEpoch 20/1000\n172/172 - 1s - loss: 0.7096 - binary_accuracy: 0.6980 - val_loss: 0.6865 - val_binary_accuracy: 0.7433\nEpoch 21/1000\n172/172 - 1s - loss: 0.7088 - binary_accuracy: 0.6991 - val_loss: 0.6859 - val_binary_accuracy: 0.7476\nEpoch 22/1000\n172/172 - 1s - loss: 0.7064 - binary_accuracy: 0.7057 - val_loss: 0.6833 - val_binary_accuracy: 0.7527\nEpoch 23/1000\n172/172 - 1s - loss: 0.7058 - binary_accuracy: 0.7146 - val_loss: 0.6822 - val_binary_accuracy: 0.7520\nEpoch 24/1000\n172/172 - 1s - loss: 0.7050 - binary_accuracy: 0.7133 - val_loss: 0.6814 - val_binary_accuracy: 0.7527\nEpoch 25/1000\n172/172 - 1s - loss: 0.7028 - binary_accuracy: 0.7115 - val_loss: 0.6801 - val_binary_accuracy: 0.7557\nEpoch 26/1000\n172/172 - 1s - loss: 0.7009 - binary_accuracy: 0.7221 - val_loss: 0.6798 - val_binary_accuracy: 0.7527\nEpoch 27/1000\n172/172 - 1s - loss: 0.7019 - binary_accuracy: 0.7162 - val_loss: 0.6771 - val_binary_accuracy: 0.7578\nEpoch 28/1000\n172/172 - 1s - loss: 0.6984 - binary_accuracy: 0.7246 - val_loss: 0.6761 - val_binary_accuracy: 0.7608\nEpoch 29/1000\n172/172 - 1s - loss: 0.6971 - binary_accuracy: 0.7283 - val_loss: 0.6746 - val_binary_accuracy: 0.7615\nEpoch 30/1000\n172/172 - 1s - loss: 0.6966 - binary_accuracy: 0.7272 - val_loss: 0.6737 - val_binary_accuracy: 0.7586\nEpoch 31/1000\n172/172 - 1s - loss: 0.6941 - binary_accuracy: 0.7418 - val_loss: 0.6738 - val_binary_accuracy: 0.7600\nEpoch 32/1000\n172/172 - 1s - loss: 0.6924 - binary_accuracy: 0.7412 - val_loss: 0.6725 - val_binary_accuracy: 0.7666\nEpoch 33/1000\n172/172 - 1s - loss: 0.6912 - binary_accuracy: 0.7423 - val_loss: 0.6719 - val_binary_accuracy: 0.7651\nEpoch 34/1000\n172/172 - 1s - loss: 0.6912 - binary_accuracy: 0.7451 - val_loss: 0.6710 - val_binary_accuracy: 0.7659\nEpoch 35/1000\n172/172 - 1s - loss: 0.6894 - binary_accuracy: 0.7558 - val_loss: 0.6690 - val_binary_accuracy: 0.7659\nEpoch 36/1000\n172/172 - 1s - loss: 0.6882 - binary_accuracy: 0.7580 - val_loss: 0.6680 - val_binary_accuracy: 0.7732\nEpoch 37/1000\n172/172 - 1s - loss: 0.6892 - binary_accuracy: 0.7474 - val_loss: 0.6677 - val_binary_accuracy: 0.7710\nEpoch 38/1000\n172/172 - 1s - loss: 0.6873 - binary_accuracy: 0.7546 - val_loss: 0.6667 - val_binary_accuracy: 0.7702\nEpoch 39/1000\n172/172 - 1s - loss: 0.6861 - binary_accuracy: 0.7633 - val_loss: 0.6666 - val_binary_accuracy: 0.7702\nEpoch 40/1000\n172/172 - 1s - loss: 0.6851 - binary_accuracy: 0.7628 - val_loss: 0.6652 - val_binary_accuracy: 0.7717\nEpoch 41/1000\n172/172 - 1s - loss: 0.6827 - binary_accuracy: 0.7734 - val_loss: 0.6643 - val_binary_accuracy: 0.7724\nEpoch 42/1000\n172/172 - 1s - loss: 0.6825 - binary_accuracy: 0.7693 - val_loss: 0.6625 - val_binary_accuracy: 0.7702\nEpoch 43/1000\n172/172 - 1s - loss: 0.6813 - binary_accuracy: 0.7712 - val_loss: 0.6629 - val_binary_accuracy: 0.7710\nEpoch 44/1000\n172/172 - 1s - loss: 0.6799 - binary_accuracy: 0.7737 - val_loss: 0.6613 - val_binary_accuracy: 0.7702\nEpoch 45/1000\n172/172 - 1s - loss: 0.6788 - binary_accuracy: 0.7790 - val_loss: 0.6604 - val_binary_accuracy: 0.7710\nEpoch 46/1000\n172/172 - 1s - loss: 0.6790 - binary_accuracy: 0.7703 - val_loss: 0.6594 - val_binary_accuracy: 0.7732\nEpoch 47/1000\n172/172 - 1s - loss: 0.6778 - binary_accuracy: 0.7796 - val_loss: 0.6585 - val_binary_accuracy: 0.7761\nEpoch 48/1000\n172/172 - 1s - loss: 0.6758 - binary_accuracy: 0.7834 - val_loss: 0.6577 - val_binary_accuracy: 0.7739\nEpoch 49/1000\n172/172 - 1s - loss: 0.6736 - binary_accuracy: 0.7852 - val_loss: 0.6585 - val_binary_accuracy: 0.7710\nEpoch 50/1000\n172/172 - 1s - loss: 0.6748 - binary_accuracy: 0.7801 - val_loss: 0.6561 - val_binary_accuracy: 0.7724\nEpoch 51/1000\n172/172 - 1s - loss: 0.6737 - binary_accuracy: 0.7776 - val_loss: 0.6555 - val_binary_accuracy: 0.7746\nEpoch 52/1000\n172/172 - 1s - loss: 0.6726 - binary_accuracy: 0.7830 - val_loss: 0.6552 - val_binary_accuracy: 0.7761\nEpoch 53/1000\n172/172 - 1s - loss: 0.6710 - binary_accuracy: 0.7909 - val_loss: 0.6549 - val_binary_accuracy: 0.7761\nEpoch 54/1000\n172/172 - 1s - loss: 0.6714 - binary_accuracy: 0.7887 - val_loss: 0.6541 - val_binary_accuracy: 0.7775\nEpoch 55/1000\n172/172 - 1s - loss: 0.6692 - binary_accuracy: 0.7920 - val_loss: 0.6532 - val_binary_accuracy: 0.7739\nEpoch 56/1000\n172/172 - 1s - loss: 0.6699 - binary_accuracy: 0.7942 - val_loss: 0.6528 - val_binary_accuracy: 0.7761\nEpoch 57/1000\n172/172 - 1s - loss: 0.6671 - binary_accuracy: 0.7922 - val_loss: 0.6527 - val_binary_accuracy: 0.7768\nEpoch 58/1000\n172/172 - 1s - loss: 0.6670 - binary_accuracy: 0.7969 - val_loss: 0.6513 - val_binary_accuracy: 0.7797\nEpoch 59/1000\n172/172 - 1s - loss: 0.6660 - binary_accuracy: 0.7991 - val_loss: 0.6504 - val_binary_accuracy: 0.7812\nEpoch 60/1000\n172/172 - 1s - loss: 0.6637 - binary_accuracy: 0.8084 - val_loss: 0.6502 - val_binary_accuracy: 0.7819\nEpoch 61/1000\n172/172 - 1s - loss: 0.6659 - binary_accuracy: 0.7993 - val_loss: 0.6505 - val_binary_accuracy: 0.7819\nEpoch 62/1000\n172/172 - 1s - loss: 0.6636 - binary_accuracy: 0.8024 - val_loss: 0.6495 - val_binary_accuracy: 0.7797\nEpoch 63/1000\n172/172 - 1s - loss: 0.6618 - binary_accuracy: 0.8027 - val_loss: 0.6493 - val_binary_accuracy: 0.7819\nEpoch 64/1000\n172/172 - 1s - loss: 0.6630 - binary_accuracy: 0.8004 - val_loss: 0.6480 - val_binary_accuracy: 0.7797\nEpoch 65/1000\n172/172 - 1s - loss: 0.6616 - binary_accuracy: 0.8077 - val_loss: 0.6479 - val_binary_accuracy: 0.7805\nEpoch 66/1000\n172/172 - 1s - loss: 0.6613 - binary_accuracy: 0.8044 - val_loss: 0.6476 - val_binary_accuracy: 0.7805\nEpoch 67/1000\n172/172 - 1s - loss: 0.6592 - binary_accuracy: 0.8120 - val_loss: 0.6468 - val_binary_accuracy: 0.7805\nEpoch 68/1000\n172/172 - 1s - loss: 0.6593 - binary_accuracy: 0.8093 - val_loss: 0.6456 - val_binary_accuracy: 0.7783\nEpoch 69/1000\n172/172 - 1s - loss: 0.6563 - binary_accuracy: 0.8146 - val_loss: 0.6461 - val_binary_accuracy: 0.7805\nEpoch 70/1000\n172/172 - 1s - loss: 0.6566 - binary_accuracy: 0.8139 - val_loss: 0.6455 - val_binary_accuracy: 0.7805\nEpoch 71/1000\n172/172 - 1s - loss: 0.6558 - binary_accuracy: 0.8150 - val_loss: 0.6446 - val_binary_accuracy: 0.7797\nEpoch 72/1000\n172/172 - 1s - loss: 0.6569 - binary_accuracy: 0.8089 - val_loss: 0.6441 - val_binary_accuracy: 0.7783\nEpoch 73/1000\n172/172 - 1s - loss: 0.6542 - binary_accuracy: 0.8106 - val_loss: 0.6435 - val_binary_accuracy: 0.7790\nEpoch 74/1000\n172/172 - 1s - loss: 0.6530 - binary_accuracy: 0.8175 - val_loss: 0.6431 - val_binary_accuracy: 0.7783\nEpoch 75/1000\n172/172 - 1s - loss: 0.6506 - binary_accuracy: 0.8265 - val_loss: 0.6431 - val_binary_accuracy: 0.7826\nEpoch 76/1000\n172/172 - 1s - loss: 0.6525 - binary_accuracy: 0.8192 - val_loss: 0.6422 - val_binary_accuracy: 0.7819\nEpoch 77/1000\n172/172 - 1s - loss: 0.6513 - binary_accuracy: 0.8239 - val_loss: 0.6419 - val_binary_accuracy: 0.7812\nEpoch 78/1000\n172/172 - 1s - loss: 0.6496 - binary_accuracy: 0.8266 - val_loss: 0.6412 - val_binary_accuracy: 0.7826\nEpoch 79/1000\n172/172 - 1s - loss: 0.6498 - binary_accuracy: 0.8208 - val_loss: 0.6400 - val_binary_accuracy: 0.7834\nEpoch 80/1000\n172/172 - 1s - loss: 0.6493 - binary_accuracy: 0.8204 - val_loss: 0.6402 - val_binary_accuracy: 0.7841\nEpoch 81/1000\n172/172 - 1s - loss: 0.6491 - binary_accuracy: 0.8228 - val_loss: 0.6394 - val_binary_accuracy: 0.7826\nEpoch 82/1000\n172/172 - 1s - loss: 0.6477 - binary_accuracy: 0.8288 - val_loss: 0.6390 - val_binary_accuracy: 0.7826\nEpoch 83/1000\n172/172 - 1s - loss: 0.6451 - binary_accuracy: 0.8330 - val_loss: 0.6392 - val_binary_accuracy: 0.7826\nEpoch 84/1000\n172/172 - 1s - loss: 0.6474 - binary_accuracy: 0.8257 - val_loss: 0.6393 - val_binary_accuracy: 0.7826\nEpoch 85/1000\n172/172 - 1s - loss: 0.6460 - binary_accuracy: 0.8266 - val_loss: 0.6387 - val_binary_accuracy: 0.7841\nEpoch 86/1000\n172/172 - 1s - loss: 0.6447 - binary_accuracy: 0.8279 - val_loss: 0.6380 - val_binary_accuracy: 0.7834\nEpoch 87/1000\n172/172 - 1s - loss: 0.6444 - binary_accuracy: 0.8266 - val_loss: 0.6366 - val_binary_accuracy: 0.7812\nEpoch 88/1000\n172/172 - 1s - loss: 0.6450 - binary_accuracy: 0.8272 - val_loss: 0.6366 - val_binary_accuracy: 0.7826\nEpoch 89/1000\n172/172 - 1s - loss: 0.6421 - binary_accuracy: 0.8318 - val_loss: 0.6363 - val_binary_accuracy: 0.7812\nEpoch 90/1000\n172/172 - 1s - loss: 0.6408 - binary_accuracy: 0.8403 - val_loss: 0.6359 - val_binary_accuracy: 0.7812\nEpoch 91/1000\n172/172 - 1s - loss: 0.6415 - binary_accuracy: 0.8312 - val_loss: 0.6361 - val_binary_accuracy: 0.7834\nEpoch 92/1000\n172/172 - 1s - loss: 0.6392 - binary_accuracy: 0.8400 - val_loss: 0.6352 - val_binary_accuracy: 0.7848\nEpoch 93/1000\n172/172 - 1s - loss: 0.6405 - binary_accuracy: 0.8332 - val_loss: 0.6354 - val_binary_accuracy: 0.7841\nEpoch 94/1000\n172/172 - 1s - loss: 0.6396 - binary_accuracy: 0.8365 - val_loss: 0.6345 - val_binary_accuracy: 0.7826\nEpoch 95/1000\n172/172 - 1s - loss: 0.6393 - binary_accuracy: 0.8391 - val_loss: 0.6346 - val_binary_accuracy: 0.7848\nEpoch 96/1000\n172/172 - 1s - loss: 0.6372 - binary_accuracy: 0.8361 - val_loss: 0.6346 - val_binary_accuracy: 0.7819\nEpoch 97/1000\n172/172 - 1s - loss: 0.6358 - binary_accuracy: 0.8407 - val_loss: 0.6350 - val_binary_accuracy: 0.7848\nEpoch 98/1000\n172/172 - 1s - loss: 0.6364 - binary_accuracy: 0.8389 - val_loss: 0.6347 - val_binary_accuracy: 0.7834\nEpoch 99/1000\n172/172 - 1s - loss: 0.6365 - binary_accuracy: 0.8369 - val_loss: 0.6329 - val_binary_accuracy: 0.7812\nEpoch 100/1000\n172/172 - 1s - loss: 0.6335 - binary_accuracy: 0.8464 - val_loss: 0.6330 - val_binary_accuracy: 0.7819\nEpoch 101/1000\n172/172 - 1s - loss: 0.6348 - binary_accuracy: 0.8425 - val_loss: 0.6329 - val_binary_accuracy: 0.7797\nEpoch 102/1000\n172/172 - 1s - loss: 0.6330 - binary_accuracy: 0.8420 - val_loss: 0.6331 - val_binary_accuracy: 0.7826\nEpoch 103/1000\n172/172 - 1s - loss: 0.6349 - binary_accuracy: 0.8403 - val_loss: 0.6318 - val_binary_accuracy: 0.7834\nEpoch 104/1000\n172/172 - 1s - loss: 0.6333 - binary_accuracy: 0.8440 - val_loss: 0.6324 - val_binary_accuracy: 0.7812\nEpoch 105/1000\n172/172 - 1s - loss: 0.6319 - binary_accuracy: 0.8431 - val_loss: 0.6316 - val_binary_accuracy: 0.7819\nEpoch 106/1000\n172/172 - 1s - loss: 0.6324 - binary_accuracy: 0.8429 - val_loss: 0.6317 - val_binary_accuracy: 0.7819\nEpoch 107/1000\n172/172 - 1s - loss: 0.6302 - binary_accuracy: 0.8538 - val_loss: 0.6310 - val_binary_accuracy: 0.7812\nEpoch 108/1000\n172/172 - 1s - loss: 0.6289 - binary_accuracy: 0.8500 - val_loss: 0.6310 - val_binary_accuracy: 0.7805\nEpoch 109/1000\n172/172 - 1s - loss: 0.6289 - binary_accuracy: 0.8465 - val_loss: 0.6307 - val_binary_accuracy: 0.7805\nEpoch 110/1000\n172/172 - 1s - loss: 0.6273 - binary_accuracy: 0.8518 - val_loss: 0.6309 - val_binary_accuracy: 0.7826\nEpoch 111/1000\n172/172 - 1s - loss: 0.6273 - binary_accuracy: 0.8485 - val_loss: 0.6299 - val_binary_accuracy: 0.7812\nEpoch 112/1000\n172/172 - 1s - loss: 0.6269 - binary_accuracy: 0.8533 - val_loss: 0.6306 - val_binary_accuracy: 0.7834\nEpoch 113/1000\n172/172 - 1s - loss: 0.6276 - binary_accuracy: 0.8493 - val_loss: 0.6296 - val_binary_accuracy: 0.7826\nEpoch 114/1000\n172/172 - 1s - loss: 0.6250 - binary_accuracy: 0.8566 - val_loss: 0.6291 - val_binary_accuracy: 0.7812\nEpoch 115/1000\n172/172 - 1s - loss: 0.6271 - binary_accuracy: 0.8522 - val_loss: 0.6294 - val_binary_accuracy: 0.7805\nEpoch 116/1000\n172/172 - 1s - loss: 0.6238 - binary_accuracy: 0.8557 - val_loss: 0.6297 - val_binary_accuracy: 0.7775\nEpoch 117/1000\n172/172 - 1s - loss: 0.6251 - binary_accuracy: 0.8524 - val_loss: 0.6291 - val_binary_accuracy: 0.7797\nEpoch 118/1000\n172/172 - 1s - loss: 0.6227 - binary_accuracy: 0.8558 - val_loss: 0.6293 - val_binary_accuracy: 0.7819\nEpoch 119/1000\n172/172 - 1s - loss: 0.6230 - binary_accuracy: 0.8560 - val_loss: 0.6292 - val_binary_accuracy: 0.7812\nEpoch 120/1000\n172/172 - 1s - loss: 0.6229 - binary_accuracy: 0.8555 - val_loss: 0.6287 - val_binary_accuracy: 0.7805\nEpoch 121/1000\n172/172 - 1s - loss: 0.6199 - binary_accuracy: 0.8593 - val_loss: 0.6289 - val_binary_accuracy: 0.7819\nEpoch 122/1000\n172/172 - 1s - loss: 0.6207 - binary_accuracy: 0.8595 - val_loss: 0.6282 - val_binary_accuracy: 0.7812\nEpoch 123/1000\n172/172 - 1s - loss: 0.6200 - binary_accuracy: 0.8637 - val_loss: 0.6280 - val_binary_accuracy: 0.7819\nEpoch 124/1000\n172/172 - 1s - loss: 0.6205 - binary_accuracy: 0.8578 - val_loss: 0.6285 - val_binary_accuracy: 0.7834\nEpoch 125/1000\n172/172 - 1s - loss: 0.6204 - binary_accuracy: 0.8593 - val_loss: 0.6277 - val_binary_accuracy: 0.7783\nEpoch 126/1000\n172/172 - 1s - loss: 0.6203 - binary_accuracy: 0.8613 - val_loss: 0.6279 - val_binary_accuracy: 0.7819\nEpoch 127/1000\n172/172 - 1s - loss: 0.6186 - binary_accuracy: 0.8626 - val_loss: 0.6280 - val_binary_accuracy: 0.7819\nEpoch 128/1000\n172/172 - 1s - loss: 0.6171 - binary_accuracy: 0.8662 - val_loss: 0.6280 - val_binary_accuracy: 0.7819\nEpoch 129/1000\n172/172 - 1s - loss: 0.6180 - binary_accuracy: 0.8620 - val_loss: 0.6276 - val_binary_accuracy: 0.7819\nEpoch 130/1000\n172/172 - 1s - loss: 0.6163 - binary_accuracy: 0.8628 - val_loss: 0.6271 - val_binary_accuracy: 0.7819\nEpoch 131/1000\n172/172 - 1s - loss: 0.6176 - binary_accuracy: 0.8599 - val_loss: 0.6271 - val_binary_accuracy: 0.7812\nEpoch 132/1000\n172/172 - 1s - loss: 0.6143 - binary_accuracy: 0.8655 - val_loss: 0.6274 - val_binary_accuracy: 0.7797\nEpoch 133/1000\n172/172 - 1s - loss: 0.6146 - binary_accuracy: 0.8670 - val_loss: 0.6270 - val_binary_accuracy: 0.7775\nEpoch 134/1000\n172/172 - 1s - loss: 0.6130 - binary_accuracy: 0.8688 - val_loss: 0.6268 - val_binary_accuracy: 0.7834\nEpoch 135/1000\n172/172 - 1s - loss: 0.6129 - binary_accuracy: 0.8708 - val_loss: 0.6265 - val_binary_accuracy: 0.7841\nEpoch 136/1000\n172/172 - 1s - loss: 0.6130 - binary_accuracy: 0.8666 - val_loss: 0.6264 - val_binary_accuracy: 0.7834\nEpoch 137/1000\n172/172 - 1s - loss: 0.6136 - binary_accuracy: 0.8688 - val_loss: 0.6261 - val_binary_accuracy: 0.7826\nEpoch 138/1000\n172/172 - 1s - loss: 0.6140 - binary_accuracy: 0.8677 - val_loss: 0.6263 - val_binary_accuracy: 0.7834\nEpoch 139/1000\n172/172 - 1s - loss: 0.6122 - binary_accuracy: 0.8679 - val_loss: 0.6260 - val_binary_accuracy: 0.7848\nEpoch 140/1000\n172/172 - 1s - loss: 0.6114 - binary_accuracy: 0.8699 - val_loss: 0.6258 - val_binary_accuracy: 0.7826\nEpoch 141/1000\n172/172 - 1s - loss: 0.6098 - binary_accuracy: 0.8724 - val_loss: 0.6254 - val_binary_accuracy: 0.7841\nEpoch 142/1000\n172/172 - 1s - loss: 0.6091 - binary_accuracy: 0.8746 - val_loss: 0.6257 - val_binary_accuracy: 0.7790\nEpoch 143/1000\n172/172 - 1s - loss: 0.6082 - binary_accuracy: 0.8770 - val_loss: 0.6260 - val_binary_accuracy: 0.7834\nEpoch 144/1000\n172/172 - 1s - loss: 0.6084 - binary_accuracy: 0.8730 - val_loss: 0.6251 - val_binary_accuracy: 0.7819\nEpoch 145/1000\n172/172 - 1s - loss: 0.6086 - binary_accuracy: 0.8746 - val_loss: 0.6259 - val_binary_accuracy: 0.7812\nEpoch 146/1000\n172/172 - 1s - loss: 0.6063 - binary_accuracy: 0.8785 - val_loss: 0.6258 - val_binary_accuracy: 0.7797\nEpoch 147/1000\n172/172 - 1s - loss: 0.6073 - binary_accuracy: 0.8779 - val_loss: 0.6257 - val_binary_accuracy: 0.7783\nEpoch 148/1000\n172/172 - 1s - loss: 0.6058 - binary_accuracy: 0.8819 - val_loss: 0.6256 - val_binary_accuracy: 0.7768\nEpoch 149/1000\n172/172 - 1s - loss: 0.6059 - binary_accuracy: 0.8794 - val_loss: 0.6252 - val_binary_accuracy: 0.7783\nEpoch 150/1000\n172/172 - 1s - loss: 0.6043 - binary_accuracy: 0.8838 - val_loss: 0.6250 - val_binary_accuracy: 0.7790\nEpoch 151/1000\n172/172 - 1s - loss: 0.6063 - binary_accuracy: 0.8786 - val_loss: 0.6249 - val_binary_accuracy: 0.7790\nEpoch 152/1000\n172/172 - 1s - loss: 0.6045 - binary_accuracy: 0.8812 - val_loss: 0.6251 - val_binary_accuracy: 0.7812\nEpoch 153/1000\n172/172 - 1s - loss: 0.6036 - binary_accuracy: 0.8823 - val_loss: 0.6257 - val_binary_accuracy: 0.7797\nEpoch 154/1000\n172/172 - 1s - loss: 0.6044 - binary_accuracy: 0.8788 - val_loss: 0.6251 - val_binary_accuracy: 0.7812\nEpoch 155/1000\n172/172 - 1s - loss: 0.6026 - binary_accuracy: 0.8859 - val_loss: 0.6251 - val_binary_accuracy: 0.7826\nEpoch 156/1000\n172/172 - 1s - loss: 0.6030 - binary_accuracy: 0.8841 - val_loss: 0.6249 - val_binary_accuracy: 0.7834\nEpoch 157/1000\n172/172 - 1s - loss: 0.6019 - binary_accuracy: 0.8830 - val_loss: 0.6247 - val_binary_accuracy: 0.7826\nEpoch 158/1000\n172/172 - 1s - loss: 0.6032 - binary_accuracy: 0.8823 - val_loss: 0.6246 - val_binary_accuracy: 0.7761\nEpoch 159/1000\n172/172 - 1s - loss: 0.6012 - binary_accuracy: 0.8872 - val_loss: 0.6248 - val_binary_accuracy: 0.7790\nEpoch 160/1000\n172/172 - 1s - loss: 0.6008 - binary_accuracy: 0.8861 - val_loss: 0.6239 - val_binary_accuracy: 0.7826\nEpoch 161/1000\n172/172 - 1s - loss: 0.6004 - binary_accuracy: 0.8858 - val_loss: 0.6242 - val_binary_accuracy: 0.7768\nEpoch 162/1000\n172/172 - 1s - loss: 0.5976 - binary_accuracy: 0.8953 - val_loss: 0.6244 - val_binary_accuracy: 0.7775\nEpoch 163/1000\n172/172 - 1s - loss: 0.5994 - binary_accuracy: 0.8876 - val_loss: 0.6243 - val_binary_accuracy: 0.7775\nEpoch 164/1000\n172/172 - 1s - loss: 0.5987 - binary_accuracy: 0.8912 - val_loss: 0.6243 - val_binary_accuracy: 0.7797\nEpoch 165/1000\n172/172 - 1s - loss: 0.5961 - binary_accuracy: 0.8987 - val_loss: 0.6244 - val_binary_accuracy: 0.7826\nEpoch 166/1000\n172/172 - 1s - loss: 0.5985 - binary_accuracy: 0.8892 - val_loss: 0.6243 - val_binary_accuracy: 0.7834\nEpoch 167/1000\n172/172 - 1s - loss: 0.5974 - binary_accuracy: 0.8872 - val_loss: 0.6248 - val_binary_accuracy: 0.7834\nEpoch 168/1000\n172/172 - 1s - loss: 0.5963 - binary_accuracy: 0.8945 - val_loss: 0.6239 - val_binary_accuracy: 0.7790\nEpoch 169/1000\n172/172 - 1s - loss: 0.5977 - binary_accuracy: 0.8885 - val_loss: 0.6240 - val_binary_accuracy: 0.7826\nEpoch 170/1000\n172/172 - 1s - loss: 0.5952 - binary_accuracy: 0.8960 - val_loss: 0.6241 - val_binary_accuracy: 0.7790\n\nTrain Accuracy\n215/215 [==============================] - 0s 2ms/step - loss: 0.5830 - binary_accuracy: 0.9019\nTest Accuracy\n24/24 [==============================] - 0s 2ms/step - loss: 0.6160 - binary_accuracy: 0.7900\n","output_type":"stream"}]},{"cell_type":"code","source":"tf.keras.metrics.BinaryAccuracy()","metadata":{"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.metrics.BinaryAccuracy at 0x7fe058e46d90>"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pylab as plt","metadata":{"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def plot_history(history):\n    # Setting\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    #acc = history.history['accuracy']\n    #val_acc = history.history['val_accuracy']\n    epochs = range(1, len(loss) + 1)\n\n    # Plotting loss\n    plt.plot(epochs, loss, 'r', label='Training loss')\n    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.figure()\n    \"\"\"\n    # Plotting accuracy\n    plt.plot(epochs, acc, 'r', label='Training acc')\n    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \"\"\"\n    plt.show()\n\n\nplot_history(history)","metadata":{"trusted":true},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 0 Axes>"},"metadata":{}}]},{"cell_type":"code","source":"%load_ext tensorboard\n#%load_ext tensorboard.notebook","metadata":{"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n","output_type":"stream"}]},{"cell_type":"code","source":"%tensorboard --logdir logs","metadata":{"trusted":true},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":"Reusing TensorBoard on port 6006 (pid 136), started 0:56:37 ago. (Use '!kill 136' to kill it.)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n      <iframe id=\"tensorboard-frame-7ed7ea493a310e04\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-7ed7ea493a310e04\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "},"metadata":{}}]},{"cell_type":"markdown","source":"# Submission","metadata":{"jupyter":{"source_hidden":true}}},{"cell_type":"code","source":"preprocess_text(df_test)","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time \n\nX_test = laser_encode(preprocess_text(df_test))\nY_test = tf.math.round( model.predict(X_test) ).numpy().astype(np.int32)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('../input/nlp-getting-started/sample_submission.csv', index_col=0)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission = pd.read_csv('../input/nlp-getting-started/sample_submission.csv', index_col=0).fillna('')\ndf_submission['target'] = Y_test\ndf_submission.to_csv('submission.csv')\n!head submission.csv","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission","metadata":{"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"       target\nid           \n0           0\n2           0\n3           1\n9           1\n11          1\n...       ...\n10861       1\n10865       1\n10868       1\n10874       1\n10875       1\n\n[3263 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10861</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10865</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10868</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10874</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10875</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3263 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Further Reading\n\nThis notebook is part of a series exploring Natural Language Processing\n- 0.74164 - [NLP Logistic Regression](https://www.kaggle.com/jamesmcguigan/disaster-tweets-logistic-regression)\n- 0.76677 - [NLP LASER Embeddings + Keras](https://www.kaggle.com/jamesmcguigan/nlp-laser-embeddings-keras)\n- 0.77536 - [NLP TF-IDF Classifier](https://www.kaggle.com/jamesmcguigan/disaster-tweets-tf-idf-classifier)\n- 0.79742 - [NLP Naive Bayes](https://www.kaggle.com/jamesmcguigan/nlp-naive-bayes)","metadata":{}}]}